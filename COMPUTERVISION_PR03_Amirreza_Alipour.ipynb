{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-23T07:51:11.164869Z",
     "iopub.status.busy": "2025-06-23T07:51:11.164264Z",
     "iopub.status.idle": "2025-06-23T07:51:23.415993Z",
     "shell.execute_reply": "2025-06-23T07:51:23.415293Z",
     "shell.execute_reply.started": "2025-06-23T07:51:11.164846Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.3/54.3 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.6/323.6 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.3/95.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m94.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install gradio --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-23T07:51:37.073256Z",
     "iopub.status.busy": "2025-06-23T07:51:37.072969Z",
     "iopub.status.idle": "2025-06-23T07:52:22.758202Z",
     "shell.execute_reply": "2025-06-23T07:52:22.757638Z",
     "shell.execute_reply.started": "2025-06-23T07:51:37.073229Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 07:52:01.495648: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1750665121.982130      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1750665122.107428      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import torch\n",
    "from diffusers import DiffusionPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-23T07:54:08.653330Z",
     "iopub.status.busy": "2025-06-23T07:54:08.652158Z",
     "iopub.status.idle": "2025-06-23T07:54:08.657764Z",
     "shell.execute_reply": "2025-06-23T07:54:08.657034Z",
     "shell.execute_reply.started": "2025-06-23T07:54:08.653301Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check for CUDA availability and set the device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-loading both Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-23T07:54:11.906266Z",
     "iopub.status.busy": "2025-06-23T07:54:11.905662Z",
     "iopub.status.idle": "2025-06-23T07:55:10.158027Z",
     "shell.execute_reply": "2025-06-23T07:55:10.157221Z",
     "shell.execute_reply.started": "2025-06-23T07:54:11.906236Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SDXL model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01dfd92a47b848febeaea3fb09117d53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model_index.json:   0%|          | 0.00/609 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b903cd4076741cabbfd415e28c3d7c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 19 files:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "873b2624d9714babada5b1da2c5c9ef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/472 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "537efb40dbb84afa83a820b22ec94a7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/565 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "293195214cac42f594e56b8f9dceec96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/575 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04b84e73def647dcbf5c3a21c4ed429a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "scheduler_config.json:   0%|          | 0.00/479 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "110fa638c48e4a4198a53b01a4263e16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/737 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b71ec39ae1241299db3ec3779868114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "text_encoder/model.fp16.safetensors:   0%|          | 0.00/246M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d1fe48f7be846e8b6d3f13d73a8e448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.06M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ac848dbfb3c47feac244744d544b912",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/460 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b4f3d44fece4bbe9ad06a6e4038015d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/725 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac613c8fef884dc0b051070891b322a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.68k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc64016b0f2d415c862c49eb0c18ae1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unet/diffusion_pytorch_model.fp16.safete(…):   0%|          | 0.00/5.14G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4edf9f9697584b7c9eafe071eac54f6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vae/diffusion_pytorch_model.fp16.safeten(…):   0%|          | 0.00/167M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8acdf844a59742879ab26d61b4eed6b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/642 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af0b082a89384bc79786edf63f527923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vae_1_0/diffusion_pytorch_model.fp16.saf(…):   0%|          | 0.00/167M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "988a460e10e14090a751f6e5b8ed5ee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDXL model loaded successfully.\n",
      "Loading SD 1.5 model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1254c46b42e48449a083dc6ba3c2f17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model_index.json:   0%|          | 0.00/541 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad6169410bc14f3fab591dbdc686784e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 15 files:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a88db37ef384b68aab85847d1196da1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/4.72k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48af0e39b720424fbeb5d6736d9a63ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/342 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef338f99f36e4484875ef6c45bccd841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/617 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbaadae4d5514f6eb2ed46fd9cd8e7b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/472 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "568ba31d5e0b417bb45e34ac28fe55a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6b02b7d59a745b683354f871526bf7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.fp16.safetensors:   0%|          | 0.00/608M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3996cc754154cdebd52cc848515bf86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "scheduler_config.json:   0%|          | 0.00/308 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80ef33255c7d4fbb9b25429ffbfa370a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/806 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0706078c3f1240baa1cebed9ac1db90b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.fp16.safetensors:   0%|          | 0.00/246M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67c406e2bde34c56b6685b0c27e1b805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.06M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b27d717c22604ddeb90858740be5a72c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aceea61722445f5b4fc814325ac3c74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/547 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae9a4529165646fb9148abc0d37f0f3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "diffusion_pytorch_model.fp16.safetensors:   0%|          | 0.00/1.72G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b336826f3bb742ad8ad29552b2e8ebdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "diffusion_pytorch_model.fp16.safetensors:   0%|          | 0.00/167M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08d15b54dc7342c082506c2a9b6f1f62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SD 1.5 model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Pre-load models to avoid reloading on every request for faster inference.\n",
    "# Using a dictionary to hold the loaded pipelines.\n",
    "pipes = {}\n",
    "\n",
    "# Load SDXL Model\n",
    "try:\n",
    "    print(\"Loading SDXL model...\")\n",
    "    pipes['stabilityai/stable-diffusion-xl-base-1.0'] = DiffusionPipeline.from_pretrained(\n",
    "        \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
    "        torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
    "        variant=\"fp16\" if device == \"cuda\" else None,\n",
    "        use_safetensors=True\n",
    "    )\n",
    "    print(\"SDXL model loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not load SDXL model: {e}\")\n",
    "\n",
    "# Load SD 1.5 Model\n",
    "try:\n",
    "    print(\"Loading SD 1.5 model...\")\n",
    "    pipes['runwayml/stable-diffusion-v1-5'] = DiffusionPipeline.from_pretrained(\n",
    "        \"runwayml/stable-diffusion-v1-5\",\n",
    "        torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
    "        variant=\"fp16\" if device == \"cuda\" else None,\n",
    "        use_safetensors=True\n",
    "    )\n",
    "    print(\"SD 1.5 model loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not load SD 1.5 model: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining function for generating image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-23T07:55:23.386552Z",
     "iopub.status.busy": "2025-06-23T07:55:23.385703Z",
     "iopub.status.idle": "2025-06-23T07:55:23.393511Z",
     "shell.execute_reply": "2025-06-23T07:55:23.392816Z",
     "shell.execute_reply.started": "2025-06-23T07:55:23.386513Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Image Generation Function ---\n",
    "def generate_image(model_name, prompt, cfg_scale, width, height):\n",
    "    \"\"\"\n",
    "    Generates an image based on the user's prompt and settings.\n",
    "    \"\"\"\n",
    "    if model_name not in pipes:\n",
    "        return None # Or return a placeholder image indicating an error\n",
    "\n",
    "    # Select the pipeline and move it to the appropriate device\n",
    "    pipe = pipes[model_name].to(device)\n",
    "\n",
    "    print(f\"Generating image with model: {model_name}\")\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "\n",
    "    # Generate the image\n",
    "    # For SDXL, width and height are passed directly. For SD1.5 they are also standard.\n",
    "    generated_image = pipe(\n",
    "        prompt=prompt,\n",
    "        guidance_scale=cfg_scale,\n",
    "        width=width,\n",
    "        height=height,\n",
    "        num_inference_steps=30 # You can also make this a user option\n",
    "    ).images[0]\n",
    "\n",
    "    return generated_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradio UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-23T07:55:30.224772Z",
     "iopub.status.busy": "2025-06-23T07:55:30.224440Z",
     "iopub.status.idle": "2025-06-23T07:55:30.833330Z",
     "shell.execute_reply": "2025-06-23T07:55:30.832574Z",
     "shell.execute_reply.started": "2025-06-23T07:55:30.224748Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
    "    gr.Markdown(\"# 🖼️ Stable Diffusion Image Generator\")\n",
    "    gr.Markdown(\"Enter a text prompt and select your desired settings to generate an image.\")\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=2):\n",
    "            prompt = gr.Textbox(\n",
    "                label=\"Prompt\",\n",
    "                show_label=False,\n",
    "                lines=3,\n",
    "                placeholder=\"e.g., An astronaut riding a horse in a photorealistic style\"\n",
    "            )\n",
    "            with gr.Row():\n",
    "                model_selector = gr.Dropdown(\n",
    "                    label=\"Model\",\n",
    "                    choices=list(pipes.keys()),\n",
    "                    value=list(pipes.keys())[0] if pipes else \"\",\n",
    "                    interactive=True\n",
    "                )\n",
    "                cfg_slider = gr.Slider(\n",
    "                    label=\"CFG Scale\",\n",
    "                    minimum=1,\n",
    "                    maximum=20,\n",
    "                    step=0.5,\n",
    "                    value=7.5\n",
    "                )\n",
    "            with gr.Row():\n",
    "                width_slider = gr.Slider(\n",
    "                    label=\"Image Width\",\n",
    "                    minimum=512,\n",
    "                    maximum=1024,\n",
    "                    step=64,\n",
    "                    value=1024\n",
    "                )\n",
    "                height_slider = gr.Slider(\n",
    "                    label=\"Image Height\",\n",
    "                    minimum=512,\n",
    "                    maximum=1024,\n",
    "                    step=64,\n",
    "                    value=1024\n",
    "                )\n",
    "            generate_btn = gr.Button(\"Generate Image\", variant=\"primary\")\n",
    "\n",
    "        with gr.Column(scale=1):\n",
    "            image_output = gr.Image(label=\"Generated Image\", show_label=False)\n",
    "\n",
    "    generate_btn.click(\n",
    "        fn=generate_image,\n",
    "        inputs=[model_selector, prompt, cfg_slider, width_slider, height_slider],\n",
    "        outputs=image_output\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-23T07:55:34.817172Z",
     "iopub.status.busy": "2025-06-23T07:55:34.816894Z",
     "iopub.status.idle": "2025-06-23T07:55:36.192490Z",
     "shell.execute_reply": "2025-06-23T07:55:36.191779Z",
     "shell.execute_reply.started": "2025-06-23T07:55:34.817149Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://c2930f8bd8daf7bfa3.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://c2930f8bd8daf7bfa3.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating image with model: stabilityai/stable-diffusion-xl-base-1.0\n",
      "Prompt: a man looking at earth from outer space\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da8478cab4c647c59adebc4d0931cd70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "demo.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
